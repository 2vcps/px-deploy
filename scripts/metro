# Install PX-Metro across the clusters

k8s_version=$(kubectl version --short | awk -Fv '/Server Version: / {print $3}')
url="https://install.portworx.com/$(cut -f 1,2 -d . <<<$px_version)?kbver=$k8s_version&c=px-cluster&stork=true&st=k8s&lh=true&k=etcd%3Ahttp%3A%2F%2Fmaster-1%3A2382"
[ -e /usr/bin/oc ] && url="$url&osft=true"
curl -so /tmp/px.yml $url
kubectl apply -f /tmp/px.yml

yum -y install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
yum install jq -y

while : ; do
  n=$(ssh node-$cluster-1 pxctl status 2>/dev/null | grep "Yes.*Online.*Up" | wc -l)
  [ $n -eq 6 ] && break
  sleep 1
  echo Waiting for Portworx cluster to come up
done

PWX_POD=$(kubectl get pods -n kube-system -l name=portworx -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
x=$(kubectl get ds/portworx -n kube-system -o json | jq -c '.spec.template.spec.containers[0].args')
x="${x%]},-cluster_domain, cluster-$cluster]"
kubectl patch ds/portworx -n kube-system --type json -p="[{\"op\": \"replace\", \"path\": \"/spec/template/spec/containers/0/args\", \"value\":$x}]"

if [ $cluster = 1 ]; then
  for i in $licenses; do
    ssh -oConnectTimeout=1 -oStrictHostKeyChecking=no node-1-1 pxctl license activate --ep UAT $i
    sleep 1
  done
  region=$(curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone | sed 's/.$//')
  aws configure set default.region $region
  instance_id=$(curl -s http://169.254.169.254/latest/meta-data/instance-id)
  vpc=$(aws ec2 describe-instances --instance-ids $instance_id --query Reservations[0].Instances[0].VpcId --output text)
  subnet=$(aws ec2 describe-instances --instance-ids $instance_id --query Reservations[0].Instances[0].SubnetId --output text)
  sg=$(aws ec2 describe-security-groups --filters Name=group-name,Values=px-deploy Name=vpc-id,Values=$vpc --query SecurityGroups[].GroupId --output text)
  instances=$(aws ec2 describe-instances --filters "Name=network-interface.vpc-id,Values=$vpc" --query "Reservations[*].Instances[*].InstanceId" --output text)
  for i in $instances; do
    aws ec2 describe-instances --instance-id $i --query Reservations[].Instances[].Tags --output text | grep -q Name.*node
   [ $? -eq 0 ] && elb_instances="$elb_instances $i"
  done
  aws elb create-load-balancer --load-balancer-name $vpc --listeners Protocol=http,LoadBalancerPort=80,InstanceProtocol=http,InstancePort=30333 --security-groups $sg --subnets $subnet
  aws elb configure-health-check --load-balancer-name $vpc --health-check Target=HTTP:30333/,Interval=10,UnhealthyThreshold=2,HealthyThreshold=2,Timeout=5
  aws elb register-instances-with-load-balancer --load-balancer-name $vpc --instances $elb_instances

  elb_dnsname=$(aws elb describe-load-balancers --query "LoadBalancerDescriptions[].{a:VPCId,b:DNSName}" --output text | awk /$vpc/'{print$2}')
  su - centos -c "DISPLAY=:0 firefox -width 1920 -height 1080" &
  while [ $(ps auxw | grep 'firefox.*childI[D]' | wc -l) -lt 4 ] ; do echo waiting for firefox; sleep 1; done
  su - centos -c "DISPLAY=:0 firefox --new-window http://$elb_dnsname" &
  while [ "$(kubectl get crd | grep -E 'migrationschedules|schedulepolicies' | wc -l)" -lt 2 ]; do
    echo waiting for CRDs
    sleep 1
  done
  kubectl apply -f /assets/metro-schedule.yml
fi
