dnf install -y pv
echo "set bell-style none" >>/etc/inputrc 
echo "set vb" >> /root/.vimrc
echo "set t_vb=" >> /root/.vimrc

kubectl create secret  generic --from-file=/root/.aws/credentials -n portworx aws-creds
kubectl patch stc/px-deploy-$cluster  --type merge  -n portworx -p '{"spec": {
  "stork": {
      "volumes": [
       {
           "mountPath": "/root/.aws",
           "name": "aws-creds",
           "readOnly": true,
           "secret": {
           "secretName": "aws-creds"
            }
        }
       ]
     }
}}'

kubectl annotate stc px-deploy-$cluster -n portworx portworx.io/service-type="LoadBalancer" --overwrite

while : ; do
  token=$(kubectl exec -n portworx -it $(kubectl get pods -n portworx -lname=portworx --field-selector=status.phase=Running | tail -1 | cut -f 1 -d " ") -- /opt/pwx/bin/pxctl cluster token show 2>/dev/null | cut -f 3 -d " ")
  echo $token | grep -Eq '\w{128}'
  [ $? -eq 0 ] && break
  sleep 5
  echo waiting for portworx
done

UUID=$(kubectl get stc -n portworx -o jsonpath='{.items[].status.clusterUid}')
S3_ACCESS_KEY=$(sed -n 's/aws_access_key_id[ =]*//p' /root/.aws/credentials 2>/dev/null | head -1)
S3_SECRET_KEY=$(sed -n 's/aws_secret_access_key[ =]*//p' /root/.aws/credentials 2>/dev/null | head -1)

S3_BUCKET_REGION=$(aws s3api get-bucket-location --bucket $DR_BUCKET --output text)
# Region us-east-1 returns "None" instead of the region name
if [ "$S3_BUCKET_REGION" = "None" ]; then
  BUCKET_REGION="us-east-1"
fi
echo "Bucket region: $S3_BUCKET_REGION"


while : ;do
    host=$(kubectl get svc -n portworx portworx-service -o jsonpath='{.status.loadBalancer.ingress[].hostname}')
    [ "$host" ] && break
    sleep 1
done

mkdir /root/drscripts
cp /root/.aws/credentials /root/drscripts/

PX_POD=$(kubectl get pods -l name=portworx -n portworx -o jsonpath='{.items[0].metadata.name}')

# run dummy "pxctl credentials list" to get driver ready
CRED_CMD="pxctl credentials list"
kubectl exec $PX_POD -n portworx -- /opt/pwx/bin/$CRED_CMD

CRED_CMD="pxctl credentials create --provider s3 --s3-access-key $S3_ACCESS_KEY --s3-secret-key $S3_SECRET_KEY --s3-region $S3_BUCKET_REGION --s3-endpoint s3.$S3_BUCKET_REGION.amazonaws.com --s3-storage-class STANDARD --bucket $DR_BUCKET clusterPair_$UUID"

PX_POD=$(kubectl get pods -l name=portworx -n portworx -o jsonpath='{.items[0].metadata.name}')
kubectl exec $PX_POD -n portworx -- /opt/pwx/bin/$CRED_CMD


storkctl generate clusterpair -n kube-system remotecluster-$cluster | sed "/insert_storage_options_here/c\    ip: $host\n    token: $token\n    mode: DisasterRecovery" >/root/drscripts/cp.yaml

# create preparation script for GKE source
cat <<EOF >>/root/drscripts/prepare_migrate_dr_source.sh
echo "[default]" >> /root/.aws/credentials
echo "aws_access_key_id = $S3_ACCESS_KEY" >> /root/aws/.credentials
echo "aws_secret_access_key = $S3_SECRET_KEY" >> /root/aws/.credentials

kubectl pxc $CRED_CMD
kubectl create secret  generic --from-file=./credentials -n portworx aws-creds
kubectl patch stc/px-deploy-1  --type merge  -n portworx -p '{"spec": {
  "stork": {
      "volumes": [
       {
           "mountPath": "/root/.aws/",
           "name": "aws-creds",
           "readOnly": true,
           "secret": {
           "secretName": "aws-creds"
            }
        }
       ]
     }
}}'
EOF

cat <<EOF >> /etc/motd
+================================================+
Howto setup multi cloud Migrate/Async DR Source
+================================================+
Copy content of /root/drscripts to source master and execute

+================================================+
EOF


